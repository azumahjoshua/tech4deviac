# Infrastructure as Code (Terraform & Localstack)

## 8. Explain the purpose of `terraform init`, `plan`, and `apply`. What is the significance of the state file?

1. ` terraform init`
This command initializes a working directory containing Terraform configuration files. It is the first command that should be run after writing a new Terraform configuration or cloning an existing configuration from version control.
    
    ### Key actions
    - Downloads and installs the required providers.
    - Initializes backend configuration for storing the state file.
    - Prepares the working directory for other commands.

2. `terraform plan`
This command previews the changes Terraform will make to reach the desired state described in the configuration files.

    ### Key features:
    - Compares the desired state (in .tf files) with the current state (in  the state file).
    - Displays an execution plan, showing resources to be created, updated,     or destroyed.
    - Summarizes changes at the end, helping to catch unintended    modifications.

3. `terraform apply`
This command is used to execute the planned actions specified in your Terraform configuration files. It takes the planned changes, which are typically generated by the terraform plan command, and creates, updates, or deletes resources to align your infrastructure with the desired state described in the code.

    ### Key actions:
    - Executes the actions proposed in terraform plan.
    - Creates, modifies, or deletes infrastructure resources.
    - Updates the Terraform state file to reflect the new state of the  infrastructure.

4. Significance of the State File (`terraform.tfstate`)

    Terraform must store state about your managed infrastructure and    configuration. This state is used by Terraform to map real world   resources to your configuration, keep track of metadata, and to improve   performance for large infrastructures.

    ### Importace of the State file
    - Keeps track of all resources managed by Terraform.
    - Maintains mappings between the resource configuration and real-world infrastructure.
    - Enables Terraform to determine what actions are required to apply updates correctly.
    - Essential for detecting drift and applying changes incrementally.
    - Supports collaboration when stored remotely (e.g., in an S3 bucket).
    - Used for resource dependency resolution.

## 9. How does Localstack help in local development and testing of cloud infrastructure? Provide a scenario where it would be especially useful.

The LocalStack Docker container provides a local development environment that emulates various AWS services. This helps developers to **test and iterate on cloud infrastructure deployments locally**, without deploying resources to the actual AWS cloud, saving both time and cost.

**How it Helps in Local Development & Testing:**
- **Cost optimization** – Running tests against LocalStack eliminates the need to use AWS services. This prevents you from incurring costs that are associated with creating, operating, and modifying those AWS resources.

- **Speed and efficiency** – Testing locally is also typically faster than deploying the AWS resources. This rapid feedback loop accelerates development and debugging. Because LocalStack runs locally, you can develop and test your Terraform configuration files without an internet connection. You can debug Terraform configuration files locally and receive immediate feedback, which streamlines the development process.

- **Consistency and reproducibility** – LocalStack provides a consistent environment for testing. This consistency helps make sure that tests yield the same results, regardless of external AWS changes or network issues.

- **Isolation** – Testing with LocalStack prevents you from accidentally affecting live AWS resources or production environments. This isolation makes it safe to experiment and test various configurations.

**Scenario: Local Development & Testing with Terraform**

Use Case: Developing Terraform Modules for AWS Networking (VPC + EC2 + RDS)

What you're building
- A **Virtual Private Cloud (VPC)** with public and private subnets.
- An **Auto Scaling Group of EC2 instances** in the private subnet.
- An **RDS PostgreSQL instance** in the private subnet.

Why LocalStack is Useful Here:
- Instead of provisioning costly real AWS resources during development, you can test your Terraform configurations locally with LocalStack.

- You can validate that your Terraform modules are creating the correct resources and dependencies (like subnet associations, routing tables, security groups, etc.) without needing actual cloud infrastructure.

- Once validated locally, the same Terraform code can be applied to the real AWS environment with minimal risk.

## 10. Write a Terraform configuration snippet to provision an S3 bucket and restrict its access to a specific IAM user.

```
provider "aws" {
  region = "us-east-1"
}

# Create an S3 bucket
resource "aws_s3_bucket" "restricted_bucket" {
  bucket = "restricted-bucket-2025-tech4dev"
  force_destroy = true
}

# Create an IAM user
resource "aws_iam_user" "s3_user" {
  name = "tech4devStudent-user"
}

# IAM Policy to allow access to the specific bucket
data "aws_iam_policy_document" "s3_user_policy" {
  statement {
    actions = [
      "s3:ListBucket"
    ]
    resources = [
      aws_s3_bucket.restricted_bucket.arn
    ]
  }

  statement {
    actions = [
      "s3:GetObject",
      "s3:PutObject",
      "s3:DeleteObject"
    ]
    resources = [
      "${aws_s3_bucket.restricted_bucket.arn}/*"
    ]
  }
}

# Attach the policy to the user
resource "aws_iam_user_policy" "user_s3_policy" {
  name   = "S3AccessPolicy"
  user   = aws_iam_user.s3_user.name
  policy = data.aws_iam_policy_document.s3_user_policy.json
}

```

- The user `tech4devStudent-user` can **only list the bucket** and **get/put/delete** objects in restricted-bucket-2025-tech4dev.

## 11. Describe how you would manage Terraform modules for a large project. What are the best practices for module versioning and reuse?

To manage terraform infrastructure using a modular approache is by organizing reusable components under a `modules/` directory. Each subfolder within `modules/` (e.g., `alb`, `vpc`, `ec2`, `iam`) encapsulates the configuration for a specific AWS resource or service. This promotes separation of concerns, reusability, and scalability across environments.

A typical folder structure looks like this:

```
envs/
  ├── dev/
  │   ├── main.tf
  │   ├── backend.tf
  │   └── terraform.tfvars
  └── prod/
      ├── main.tf
      ├── backend.tf
      └── terraform.tfvars

modules/
  ├── alb/
  ├── domain/
  ├── ec2/
  ├── ecr/
  ├── iam/
  ├── security_group/
  └── vpc/

├── main.tf
├── variables.tf
├── outputs.tf
├── providers.tf
├── backend.tf
├── destroy.sh
├── deploy.sh

```
Each environment (`dev`, `prod`) contains its own configuration files and variable overrides, allowing infrastructure to be deployed consistently across stages while maintaining isolation.

At the root level, we can call the modules like this

```
module "vpc" {
  source               = "./modules/vpc"
  vpc_name             = "clm-vpc"
  vpc_cidr             = "10.0.0.0/16"
  availability_zones   = ["us-east-1a", "us-east-1b"]
  public_subnet_cidrs  = ["10.0.1.0/24", "10.0.2.0/24"]
  private_subnet_cidrs = ["10.0.3.0/24", "10.0.4.0/24", "10.0.5.0/24", "10.0.6.0/24"]
}

```

For module versioning and reuse across teams or repositories, I follow these best practices:
- Semantic versioning: Tag stable releases of shared modules (`v1.0.0`, `v1.1.0`, etc.)
- Remote module sources: Use GitHub or a private module registry for sharing modules across projects.        

```
module "ec2" {
  source = "git::https://github.com/my-org/terraform-modules.git//ec2?ref=v1.2.0"
}

```
This structure makes the codebase modular, easier to maintain, and scalable for multiple teams and environments.